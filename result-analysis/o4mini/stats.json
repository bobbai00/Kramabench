{
  "config": {
    "threshold": 0.9,
    "code_agent": "CodeAgentSystemO4Mini",
    "dataflow_system": "DataflowSystemO4Mini"
  },
  "total_tasks": 104,
  "accurate_tasks_count": 75,
  "approximate_tasks_count": 29,
  "categories": {
    "both_succeed": 46,
    "dataflow_succeed": 10,
    "code_succeed": 5,
    "both_failed": 43
  },
  "categories_accurate_only": {
    "both_succeed": 36,
    "dataflow_succeed": 6,
    "code_succeed": 3,
    "both_failed": 30
  },
  "domain_breakdown": {
    "archeology": {
      "both_succeed": 4,
      "dataflow_succeed": 1,
      "code_succeed": 0,
      "both_failed": 7,
      "code_mean_score": 0.3333,
      "dataflow_mean_score": 0.4167
    },
    "astronomy": {
      "both_succeed": 2,
      "dataflow_succeed": 2,
      "code_succeed": 0,
      "both_failed": 8,
      "code_mean_score": 0.2083,
      "dataflow_mean_score": 0.4167
    },
    "biomedical": {
      "both_succeed": 4,
      "dataflow_succeed": 2,
      "code_succeed": 1,
      "both_failed": 2,
      "code_mean_score": 0.5556,
      "dataflow_mean_score": 0.6667
    },
    "environment": {
      "both_succeed": 7,
      "dataflow_succeed": 3,
      "code_succeed": 3,
      "both_failed": 7,
      "code_mean_score": 0.52,
      "dataflow_mean_score": 0.544
    },
    "legal": {
      "both_succeed": 21,
      "dataflow_succeed": 1,
      "code_succeed": 0,
      "both_failed": 8,
      "code_mean_score": 0.7,
      "dataflow_mean_score": 0.7333
    },
    "wildfire": {
      "both_succeed": 8,
      "dataflow_succeed": 1,
      "code_succeed": 1,
      "both_failed": 11,
      "code_mean_score": 0.4683,
      "dataflow_mean_score": 0.4524
    }
  },
  "domain_breakdown_accurate_only": {
    "archeology": {
      "both_succeed": 4,
      "dataflow_succeed": 1,
      "code_succeed": 0,
      "both_failed": 7,
      "accurate_task_count": 12
    },
    "astronomy": {
      "both_succeed": 2,
      "dataflow_succeed": 1,
      "code_succeed": 0,
      "both_failed": 5,
      "accurate_task_count": 8
    },
    "biomedical": {
      "both_succeed": 3,
      "dataflow_succeed": 1,
      "code_succeed": 1,
      "both_failed": 2,
      "accurate_task_count": 7
    },
    "environment": {
      "both_succeed": 6,
      "dataflow_succeed": 3,
      "code_succeed": 2,
      "both_failed": 5,
      "accurate_task_count": 16
    },
    "legal": {
      "both_succeed": 16,
      "dataflow_succeed": 0,
      "code_succeed": 0,
      "both_failed": 7,
      "accurate_task_count": 23
    },
    "wildfire": {
      "both_succeed": 5,
      "dataflow_succeed": 0,
      "code_succeed": 0,
      "both_failed": 4,
      "accurate_task_count": 9
    }
  },
  "score_statistics": {
    "overall": {
      "code_agent": {
        "mean": 0.507051282051282,
        "min": 0.0,
        "max": 1.0,
        "count": 104
      },
      "dataflow": {
        "mean": 0.5613553113553114,
        "min": 0.0,
        "max": 1.0,
        "count": 104
      }
    },
    "by_domain": {
      "archeology": {
        "code_agent_mean": 0.3333333333333333,
        "dataflow_mean": 0.4166666666666667,
        "count": 12
      },
      "astronomy": {
        "code_agent_mean": 0.20833333333333334,
        "dataflow_mean": 0.4166666666666667,
        "count": 12
      },
      "biomedical": {
        "code_agent_mean": 0.5555555555555556,
        "dataflow_mean": 0.6666666666666666,
        "count": 9
      },
      "environment": {
        "code_agent_mean": 0.52,
        "dataflow_mean": 0.5440476190476191,
        "count": 20
      },
      "legal": {
        "code_agent_mean": 0.7,
        "dataflow_mean": 0.7333333333333333,
        "count": 30
      },
      "wildfire": {
        "code_agent_mean": 0.46825396825396826,
        "dataflow_mean": 0.4523809523809524,
        "count": 21
      }
    }
  },
  "selected_samples": {
    "both_succeed": [
      {
        "task_id": "archeology-easy-4",
        "code_score": 1.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "wildfire-easy-15",
        "code_score": 1.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "legal-easy-5",
        "code_score": 1.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "legal-easy-27",
        "code_score": 1.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "legal-hard-28",
        "code_score": 1.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      }
    ],
    "dataflow_succeed": [
      {
        "task_id": "environment-easy-6",
        "code_score": 0.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 1.0
      },
      {
        "task_id": "environment-easy-4",
        "code_score": 0.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 1.0
      },
      {
        "task_id": "environment-hard-10",
        "code_score": 0.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 1.0
      },
      {
        "task_id": "archeology-easy-11",
        "code_score": 0.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 1.0
      },
      {
        "task_id": "biomedical-hard-5",
        "code_score": 0.0,
        "dataflow_score": 1.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 1.0
      }
    ],
    "code_succeed": [
      {
        "task_id": "environment-easy-3",
        "code_score": 1.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": -1.0
      },
      {
        "task_id": "environment-easy-1",
        "code_score": 1.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": -1.0
      },
      {
        "task_id": "biomedical-hard-1",
        "code_score": 1.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": -1.0
      }
    ],
    "both_failed": [
      {
        "task_id": "legal-easy-21",
        "code_score": 0.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "wildfire-hard-4",
        "code_score": 0.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "legal-hard-24",
        "code_score": 0.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "environment-hard-19",
        "code_score": 0.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      },
      {
        "task_id": "archeology-hard-1",
        "code_score": 0.0,
        "dataflow_score": 0.0,
        "code_metric": "success",
        "dataflow_metric": "success",
        "is_accurate": true,
        "score_diff": 0.0
      }
    ]
  }
}